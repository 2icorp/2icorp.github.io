---
title: "[논문리뷰] OmniGen"
last_modified_at: 2024-10-12
categories:
  - 논문리뷰
tags:
  - Text to Image
excerpt: ""
use_math: true
classes: wide
---

# OmniGen Review

### 1. **OmniGen: 통합 이미지 생성**

- **저자**: Shitao Xiao, Yueze Wang, Junjie Zhou, Huaying Yuan, Xingrun Xing, Ruiran Yan, Shuting Wang, Tiejun Huang, Zheng Liu (교신 저자)
- **소속**: Beijing Academy of Artificial Intelligence

---

### 2. **요약 (Abstract)**

- OmniGen은 통합 프레임워크를 도입하여 텍스트-이미지 생성뿐만 아니라 이미지 편집, 객체 기반 생성, 시각적 조건 기반 생성을 지원하는 모델이다.
- 기존 모델들처럼 ControlNet 같은 추가 모듈을 사용할 필요가 없으며, 복잡한 구조 없이 작업 흐름을 간소화한다.
- 이 모델은 다양한 도메인에서 지식을 전이하며, 미지의 작업이나 새로운 기능을 다룰 수 있는 능력을 보여준다.
- 이 연구의 리소스는 오픈소스로 제공되며, 관련 연구의 발전을 도모한다.

---

### 3. **소개 (Introduction)**

- *Artificial General Intelligence (AGI)**를 추구하는 과정에서 다양한 작업을 처리할 수 있는 다목적 모델에 대한 수요가 증가하고 있다.
- *Large Language Models (LLMs)**는 자연어 처리(NLP)에서 다목적 기능을 발휘하며 혁신을 일으켰지만, 이미지 생성에서는 이에 상응하는 모델이 아직 나타나지 않았다.
- 기존의 **Stable Diffusion**이나 **DALL-E** 같은 모델은 특정 작업에만 능숙하지만, 범용적으로 사용하기에는 한계가 있다.
- OmniGen은 다양한 작업을 하나의 프레임워크에서 처리할 수 있는 유일한 솔루션을 제공하며, 텍스트-이미지 생성부터 컴퓨터 비전 작업(예: 가장자리 검출, 인체 자세 인식)까지 처리할 수 있다.

---

### 4. **OmniGen 프레임워크**

- **디자인 원칙**:
    - **범용성**: 다양한 형태의 이미지와 텍스트 입력을 처리 가능.
    - **간결성**: 복잡한 구조나 추가 컴포넌트 없이 간단한 구조로 설계.
- **네트워크 아키텍처**:
    - *Variational Autoencoder (VAE)**와 **Transformer**만으로 구성되며, 별도의 텍스트나 이미지 인코더가 필요 없다.
    - 텍스트와 이미지를 통합하여 멀티모달 프롬프트로 처리.
- **어텐션 메커니즘**:
    - 텍스트 시퀀스에는 인과적 어텐션을, 이미지 패치에는 양방향 어텐션을 적용하여 다양한 입력 조건 간 상호작용을 가능하게 한다.
- **추론(Inference)**: **flow matching method**를 사용해 목표 속도를 예측하며, 50단계의 기본 추론 단계를 거쳐 이미지 생성.

---

### 5. **훈련 전략**

- **Rectified Flow Optimization**: 노이즈화된 데이터, 타임스텝, 조건을 바탕으로 목표 속도를 직접적으로 예측.
- **증폭된 손실 가중치**: 이미지 편집 작업에서 손실을 변경이 발생한 영역에 더 크게 적용해 학습 효율을 높인다.
- **훈련 파이프라인**: 이미지 해상도를 점진적으로 증가시키는 5단계 훈련 과정으로, 이미지 생성의 미적 품질을 향상.
- **하드웨어**: **104 A800 GPU**를 사용한 실험 진행.

---

### 6. **X2I 데이터셋**

- **X2I 데이터셋**은 **다중 작업 처리**를 지원하기 위해 설계되었으며, 약 **0.1억 장의 이미지**로 구성되어 있다.
- **데이터 출처**:
    - **텍스트에서 이미지로(Text to Image)**: **LAION-Aesthetic**, **Recap-DataComp**, 내부적으로 수집된 고품질 이미지 사용.
    - **멀티모달에서 이미지로(Multi-modal to Image)**: 혼합 모달 프롬프트를 지원하며, 이미지 편집, 스타일 변환, 가상 착용 데이터를 포함.
    - **객체 기반 생성(Subject-driven Generation)**: **GRIT-Entity 데이터셋**과 **웹 이미지 데이터셋** 사용.
    - **컴퓨터 비전 작업(Computer Vision Tasks)**: 엣지 검출, 깊이 매핑, 인체 자세 인식 등 기존 비전 작업을 통합.
    - **Few-shot 학습**: 학습 효율성을 높이기 위해 각 작업에서 예제를 추출하여 모델이 소수의 예제로도 새로운 작업을 처리할 수 있도록 구성.

---

### 7. **실험 결과**

- **텍스트에서 이미지로(Text-to-Image) 생성**: **GenEval 벤치마크**에서 평가한 결과, OmniGen은 **SD3**, **DALLE-3** 같은 모델에 비해 적은 매개변수로도 유사한 성능을 보였다.
- **이미지 편집**: **InstructPix2Pix** 같은 모델과 비교해, 객체 제거, 색상 변경, 배경 수정 등 다양한 편집 작업에서 유사한 성능을 보였다.
- **DreamBooth 평가**: 객체 충실도와 텍스트 충실도 측면에서 최첨단 모델들과 유사한 성능을 입증.
- **시각적 조건 제어(Visual Conditional Controls)**: 분할 마스크, 엣지 검출, 깊이 매핑 작업에서 최적의 결과를 기록.
- **컴퓨터 비전 작업**: Deraining, deblurring, 인체 자세 인식 등 기존 작업을 효과적으로 처리.

---

### 8. **Emerging Capabilities**

- **작업 구성(Task Composition)**: 이미지 인페인팅(복원)과 특정 영역 색상 변경 같은 다중 작업을 동시에 처리 가능.
- **암묵적 작업 결합(Implicit Combination of Tasks)**: 예를 들어, 깊이 매핑이나 포즈 인식을 기반으로 이미지 생성 시 추가적인 전처리 없이 작업을 처리.
- **In-context Learning**: 몇 가지 예시만으로 새로운 작업이나 객체를 성공적으로 생성할 수 있는 소수 샷 학습 기능을 보여준다.

---

### 9. **추론 능력(Reasoning Ability)과 Chain of Thought**

- **추론 능력(Reasoning Ability)**: 이미지에서 문맥을 바탕으로 객체를 식별할 수 있으며, 예를 들어 싱크대를 찾아야 한다는 지시를 이해하고 적절한 객체를 강조.
- **Chain of Thought**: 인간이 그림을 그리는 방식과 유사하게 이미지를 점진적으로 개선하는 과정으로, 더 세밀하게 이미지를 생성한다.

---

### 10. **한계점 (Limitations)**

- **텍스트 민감성**: 다른 모델들처럼 텍스트 프롬프트의 품질에 따라 결과가 민감하게 달라진다.
- **텍스트 렌더링**: 긴 텍스트를 생성하는 데 어려움을 겪는다.
- **생성된 이미지의 세부 묘사**: 손이나 얼굴 같은 세밀한 부분에서 오류가 발생할 수 있다.
- **미지의 이미지 타입 처리**: OmniGen은 새로운 이미지 타입(예: surface normals)을 처리하는 데 한계가 있다.

---

### 결론

OmniGen은 텍스트-이미지 생성과 더불어 이미지 편집, 객체 기반 생성, 시각적 조건 기반 생성 등 다양한 작업을 하나의 모델로 처리할 수 있는 혁신적인 모델로, 범용성을 갖춘 이미지 생성의 새로운 표준을 제시한다. 특히 복잡한 추가 모듈 없이 단순화된 구조로 작업을 처리하며, 다양한 도메인 간 지식 전이를 통해 새로운 작업을 처리할 수 있는 능력을 보여준다. 그러나 텍스트 프롬프트의 민감성과 긴 텍스트 렌더링, 세부 묘사의 오류 같은 몇 가지 한계점이 남아 있으며, 더 많은 데이터로 추가 훈련을 통해 이러한 문제를 해결할 수 있을 것이다.

## 최신 글
<ul>
  {% for post in site.posts %}
    <li>
      <a href="{{ post.url }}">{{ post.title }}</a>
      <span>{{ post.date | date: "%B %d, %Y" }}</span>
    </li>
  {% endfor %}
</ul>


